\documentclass[a4paper,12pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian,english]{babel}
\usepackage{amsmath}
\usepackage{cmap}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{setspace}
\usepackage[left=2cm, right=1.5cm, top=2cm, bottom=2cm]{geometry}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}
\lstset{
	language=C++,
	basicstyle=\small\ttfamily,
	keywordstyle=\color{blue},
	commentstyle=\color{green!40!black},
	stringstyle=\color{purple},
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	breaklines=true,
	frame=single,
	backgroundcolor=\color{gray!10},
	rulecolor=\color{black!30},
	showstringspaces=false,
	extendedchars=\true, % Включение расширенных символов, включая русский текст
}
\begin{document}
	
	\begin{center}
		\hfill \break
		\textbf{\large{Министерство науки и высшего образования Российской Федерации\\
				Федеральное государственное автономное образовательное\\
				учреждение высшего образования}}
		\\
		\large{\textbf{«КАЗАНСКИЙ (ПРИВОЛЖСКИЙ) ФЕДЕРАЛЬНЫЙ УНИВЕРСИТЕТ»}}\\
		\hfill \break
		\large{ИНСТИТУТ ВЫЧИСЛИТЕЛЬНОЙ МАТЕМАТИКИ\\ И ИНФОРМАЦИОННЫХ ТЕХНОЛОГИЙ}\\
		\hfill \break
		\large{Кафедра прикладной математики и искусственого интеллекта}\\
		\hfill\break
		\hfill \break
		\large{Направление подготовки: 01.03.04 – Прикладная математика}\\
		\hfill \break
		\hfill \break
		\textbf{\large{ОТЧЁТ}}\\
		\large{По дисциплине <<Численные методы>>}\\
		\large{на тему:}\\
		\large{<<Система линейных алгебраических уравнений>>}\\
		\hfill \break
		\hfill \break
	\end{center}
	
	\hfill \break
	\begin{flushright}
		
		\large{Выполнил:}
		
		\large{студент группы 09-222}
		
		\large{Ахметзянов К.Ф.}
		
		\large{Проверил:}
		
		\large{ассистент Глазырина О.В.}
		
	\end{flushright}
	\vfill
	\begin{center} \large{Казань, 2024 год} \end{center}
	\thispagestyle{empty}
	
	
	\newpage
	\begin{center}
		\renewcommand{\contentsname}{Содержание}
		\fontsize{14}{1.15}\selectfont
		\mdseries\selectfont{\tableofcontents}
		\newpage
	\end{center}
	\setlength{\parindent}{1.25cm}
	\newpage
	\selectfont\onehalfspacing{
		\section{Постановка задачи}
		\hspace{1.25cm}Решить систему линейных алгебраических уравнений:
		\begin{equation}\label{eq:main_sys}
			\begin{cases}
				&(a_1 + a_2 + h^2g_1)y_1 - a_2y_2 = f_1h^2,\\
				&\hspace{1cm}\dots \quad \dots \quad \dots \quad \dots\\
				&-a_iy_{i-1} + (a_i + a_{i+1} + h^2g_i)y_i - a_{i+1}y_{i+1} = f_ih^2,\\
				&\hspace{1cm}\dots \quad \dots \quad \dots \quad \dots\\
				&(a_{n-1} + a_{n} + h^2g_{n-1})y_{n-1} - a_{n-1}y_{n-2} = f_{n-1}h^2.\\
			\end{cases}
		\end{equation}
		
		Здесь $a_i = p(ih),\;g_i = q(ih),\;f_i = f(ih),\;f(x) = -(p(x)u'(x))' + q(x)u(x),\;\\h = 1/n,\;p,\;q,\;u\;~-$ заданные функции.
		
		Данную систему решить методом прогоки и итерационными методами:
		\begin{enumerate}[label = \arabic*.]
			\item метод Зейделя.
			\item метод верхней релаксации.
			\item метод наискорейшего спуска.
		\end{enumerate}
		
		Во всех итерационных методах вычисления продолжать до выполнения условия:
		\begin{equation*}
			\max_{1 \le i \le n - 1} \left|r_{i}^{k}\right| \le \varepsilon,
		\end{equation*}
		$r\;~-$ вектор невязки, $\varepsilon\;~-$ заданное число.
		
		\textbf{Исходные данные:} $n = 10,\; n = 50,\;\varepsilon = h^3,\;u(x) = x^{\alpha}(1-x)^{\beta},\;\\p(x) = 1 + x^{\gamma},\;g(x) = x + 1,\;\alpha = 1,\;\beta = 1,\;\gamma = 2.$
		
		Для сравнения результатов вычисления составим таблицы и подведём выводы.
		\section{Ход работы}
		\subsection{Метод прогонки}
		\hspace*{1.25cm} Метод прогонки состоит из двух этапов: прямой ход (определение прогоночных коэффициентов), 
		обратных ход (вычисление неизвестных $y_i$).
		
		Основным преимуществом является экономичность $~-$ максимально использование структуры исходной системы.
		
		К недостаткам же можно отнести то, что с каждой итерацией накапливается ошибка округления.
		
		% Запишем систему \eqref{eq:main_sys} в следующем виде:
		% \begin{equation}
			%     \begin{cases}
				%         &-b_1y_1 + c_1y_2 = f_1,\\
				%         &\hspace{1cm}\dots \quad \dots \quad \dots \quad \dots\\
				%         &a_iy_{i-1} -b_iy_i + c_iy_{i+1} = f_i,\\
				%         &\hspace{1cm}\dots \quad \dots \quad \dots \quad \dots\\
				%         &b_ny_n - a_{n-1}y_{n-1} = f_{n-1}.\\
				%     \end{cases}
			% \end{equation}
		
		Реализуем прямой ход метода и найдём прогоночные коэффициенты:
		\begin{equation}
			\begin{cases}
				\alpha_1 = \dfrac{a_1}{a_0 + a_1 + h^2g_1},\\
				\alpha_{i+1} = \dfrac{a_{i+1}}{a_i + a_{i+1} + h^2g_i - \alpha_ia_i}, \quad i = \overline{2, n - 1};\\
			\end{cases}
		\end{equation}
		\begin{equation}
			\begin{cases}
				\beta_1 = \dfrac{f_0h^2}{a_0 + a_1 + h^2g_1},\\
				\beta_{i+1} = \dfrac{f_ih^2 + \beta_ia_i}{a_i + a_{i+1} + h^2g_i - \alpha_ia_i}, \quad i = \overline{2, n - 1};\\
			\end{cases}
		\end{equation}
		
		Обратных ход метода:
		\begin{equation}
			\begin{cases}
				y_n = \beta_{n+1};\\
				y_i = \alpha_{i+1}y_{i+1} + \beta_{i+1}, \quad i = \overline{n-1, 0};\\
			\end{cases}
		\end{equation}
		
		Формулы (2-4) являются методом Гаусса, записанным применительно трёх\-диаго\-наль\-ной системы уравнений. 
		Метод может быть реализован только в случае, когда в формулах (2) и (3) все знаменатели отличны от нуля, 
		то есть условие выполняется, когда матрица системы (1) имеет диагональное препобладание.
		
		Проделаем вычисления и составим таблицу для $n = 10$, для $n = 50$:
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|}
				\hline
				$ih$ & $y\_i$ & $u(ih)$ & $\epsilon$ \\
				\hline
				0.10 & 0.106769 & 0.090000 & 0.016769 \\
				\hline
				0.20 & 0.184376 & 0.160000 & 0.024376 \\
				\hline
				0.30 & 0.235499 & 0.210000 & 0.025499 \\
				\hline
				0.40 & 0.263158 & 0.240000 & 0.023158 \\
				\hline
				0.50 & 0.270334 & 0.250000 & 0.020334 \\
				\hline
				0.60 & 0.259690 & 0.240000 & 0.019690 \\
				\hline
				0.70 & 0.233435 & 0.210000 & 0.023435 \\
				\hline
				0.80 & 0.193281 & 0.160000 & 0.033281 \\
				\hline
				0.90 & 0.140478 & 0.090000 & 0.050478 \\
				\hline
				1.00 & 0.075876 & 0.000000 & 0.075876 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 1 - значения метода прогонки для $n = 10$}}
		\end{table}
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|}
				\hline
				$ih$ & $y\_i$ & $u(ih)$ & $\epsilon$ \\
				\hline
				0.10 & 0.101429 & 0.090000 & 0.011429 \\
				\hline
				0.20 & 0.174182 & 0.160000 & 0.014182 \\
				\hline
				0.30 & 0.220545 & 0.210000 & 0.010545 \\
				\hline
				0.40 & 0.243242 & 0.240000 & 0.003242 \\
				\hline
				0.50 & 0.245064 & 0.250000 & 0.004936 \\
				\hline
				0.60 & 0.228573 & 0.240000 & 0.011427 \\
				\hline
				0.70 & 0.195932 & 0.210000 & 0.014068 \\
				\hline
				0.80 & 0.148846 & 0.160000 & 0.011154 \\
				\hline
				0.90 & 0.088567 & 0.090000 & 0.001433 \\
				\hline
				1.00 & 0.015952 & 0.000000 & 0.015952 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 2 - значения метода прогонки для $n = 50$}}
		\end{table}
		\subsection{Метод Зейделя}
		\hspace*{1.25cm}Для больших систем вида $Ax=b$ предпочтительнее оказываются итерационные методы. 
		Основная идея данных методов состоит в построении последовательности векторов $x^k, \; k=1,2,\dots,$ 
		сходящейся к решению исходной системы. За приближенное решение принимается вектор $x^k$ при достаточно большом $k$.
		
		Будем считать, что все диагональные элементы матрицы $А$ из полной системы $Ax=b$ отличны от нуля. 
		Представим эту систему, разрешая каждое уранвение относительно переменной, стоящей на главной диагонали: 
		\begin{equation}
			x_i = - \sum\limits_{j=1}^{i-1} \frac{a_{ij}}{a_{ii}}x_j - \sum\limits_{j=i+1}^n \frac{a_{ij}}{a_{ii}}x_j+\frac{b_i}{a_{ii}}, \quad i = \overline{1,n}.
			\label{5}
		\end{equation}
		
		Выберем некоторое начальное приближение $x^0=(x_1^0, x_2^0, {\dots}, x_n^0)^T$. 
		Построим последова\-тель\-ность векторов $x^1, x^2, {\dots},$ определяя вектор $x^{k+1}$ по уже найденному вектору $x^k$ при помощи соотношения: 
		\begin{equation}
			x_i^{k+1}= - \sum\limits_{j=1}^{i-1} \frac{a_{ij}}{a_{ii}}x_j^k - \sum\limits_{j=i+1}^n \frac{a_{ij}}{a_{ii}}x_j^k+\frac{b_i}{a_{ii}}, \quad i = \overline{1,n}. 
			\label{6}
		\end{equation}
		
		Формула (\ref{6}) определяют итерационный метод решения системы (\ref{5}), называемый мето\-дом Якоби или методом простой итерации.
		
		Метод Якоби допускает естественную модификацию: при вычислении $x_i^{k+1}$ 
		будем использовать уже найденные компоненты вектора $x^{k+1}$, то есть $x_1^{k+1},\;x_2^{k+1},\;\dots,\;x_{i-1}^{k+1}$. 
		В результате приходим к итерационному методу Зейделя:
		\begin{equation}
			x_i^{k+1}= - \sum\limits_{j=1}^{i-1} \frac{a_{ij}}{a_{ii}}x_j^{k+1} - \sum\limits_{j=i+1}^n \frac{a_{ij}}{a_{ii}}x_j^k+\frac{b_i}{a_{ii}}, \quad i = \overline{1,n}. 
			\label{7}
		\end{equation}
		
		Запишем формулу (\ref{7}) для нашей системы \eqref{eq:main_sys}:
		\begin{equation}
			y_i^{k+1}=  -\sum\limits_{j=1}^{i-1}\frac{a_j}{a_i+a_{i+1}+h^2 g_i}y_j^{k+1} \; - \;\sum\limits_{j=i+1}^{n}\frac{a_{j}}{a_i+a_{i+1}+h^2 g_i}y_j^k\; +\; \frac{f_i h^2}{a_i+a_{i+1}+h^2 g_i},$$$$
			i=\overline{1, n-1};
			\label{8}
		\end{equation}
		
		Вычисления продолжаем, пока не выполнится условие:
		$$\max\limits |r_i^k| \leq \varepsilon,$$
		где $r^k ~-$ вектор невязки для $k$-той итерации $r^k=Ay^k-f, \quad \varepsilon=h^3.$
		
		Составим таблицы вычесленных результатов для $n = 10$, для $n = 50$, 
		в которых будем сравнивать значения метода прогонки и метода Зейделя для точки $i,\; i = \overline{0, n - 1}$, 
		найдём модуль их разности и значение $k$, при котором была достигнута необходимая точность.
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				$i$ & $y_i$ & $y_i^{k}$ & $\epsilon$ & $k$ \\
				\hline
				0 & 0.106769 & 0.103847 & 0.002922 & 37 \\
				\hline
				1 & 0.184376 & 0.179133 & 0.005243 & 37 \\
				\hline
				2 & 0.235499 & 0.228694 & 0.006805 & 37 \\
				\hline
				3 & 0.263158 & 0.255599 & 0.007559 & 37 \\
				\hline
				4 & 0.270334 & 0.262779 & 0.007555 & 37 \\
				\hline
				5 & 0.259690 & 0.252777 & 0.006913 & 37 \\
				\hline
				6 & 0.233435 & 0.227639 & 0.005795 & 37 \\
				\hline
				7 & 0.193281 & 0.188898 & 0.004383 & 37 \\
				\hline
				8 & 0.140478 & 0.137629 & 0.002849 & 37 \\
				\hline
				9 & 0.075876 & 0.074529 & 0.001347 & 37 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 3 - значения метода Зейделя для $n = 10$}}
		\end{table}
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				$i$ & $y_i$ & $y_i^{k}$ & $\epsilon$ & $k$ \\
				\hline
				0 & 0.022665 & 0.022564 & 0.000101 & 1155 \\
				\hline
				10 & 0.185482 & 0.184502 & 0.000981 & 1155 \\
				\hline
				20 & 0.245190 & 0.243795 & 0.001395 & 1155 \\
				\hline
				30 & 0.223275 & 0.222033 & 0.001242 & 1155 \\
				\hline
				40 & 0.137813 & 0.137131 & 0.000682 & 1155 \\
				\hline
				49 & 0.015952 & 0.015886 & 0.000065 & 1155 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 4 - значения метода Зейделя для $n = 50$}}
		\end{table}
		\clearpage
		\subsection{Метод верхней релаксации}
		\hspace{1.25cm}Во многих ситуациях существенного ускорения сходимости можно добиться за счет введения так называемого итерационного параметра. 
		Рассмотрим итерационный процесс:
		\begin{equation}
			x_i^{k+1}=(1-\omega)x_i^k+\omega \bigg( - \sum\limits_{j=1}^{i-1} \frac{a_{ij}}{a_{ii}}x_j^{k+1}- \sum\limits_{j=i+1}^{n} \frac{a_{ij}}{a_{ii}}x_j^{k}+\frac{b_i}{a_{ii}}\bigg),
			$$$$ i=1,2, \dots, n, \quad k=0,1, \dots \; .
			\label{9}
		\end{equation}
		
		Этот метод называется методом релаксации -- одним из наиболее эффективных и широко используемых итерационных 
		методов для решения систем линейных алгебраичес\-ких уравнений. Значение $\omega $ -- называется релаксационным параметром. 
		При $\omega = 1$ метод переходит в метод Зейделя. При $\omega \in (1,2)$ -- это метод верхней релаксации, при $\omega \in (0,1)$ -- метод нижней релаксации. 
		Ясно, что по затратам памяти и объему вычислений на каждом шаге итераций метод релаксации не отличается от метода Зейделя.
		
		Преобразуем формулу (9) относительно нашей системы:
		\begin{equation}
			y_i^{k+1}=(1-\omega)y_i^k+\omega  \bigg(-\sum\limits_{j=1}^{i-1}\frac{a_j}{a_i+a_{i+1}+h^2 g_i}y_j^{k+1} \; - \;\sum\limits_{j=i+1}^{n}\frac{a_{j}}{a_i+a_{i+1}+h^2 g_i}y_j^k\; +\; \frac{f_i h^2}{a_i+a_{i+1}+h^2 g_i}\bigg),$$$$
			i=\overline{1, n-1};
			\label{10}
		\end{equation}
		
		Параметр $\omega$ следует выбирать так, чтобы метод релаксации сходился наиболее быстро. 
		Нужно отметить, что оптимальный параметр для метода верхней релаксации лежит вблизи 1,8. 
		Заполним таблицы, в которых приведём значения параметра $\omega$ и количство итераций $k$:
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|}
				\hline
				$\omega$ & $k$\\
				\hline
				1.1 & 31\\ \hline
				1.2 & 25\\ \hline
				1.3 & 20\\ \hline
				1.4 & 17\\ \hline
				1.5 & 13\\ \hline
				1.6 & 11\\ \hline
				1.7 & 16\\ \hline
				1.8 & 22\\ \hline
				1.9 & 53\\ \hline
			\end{tabular}
			\caption*{\small{Таблица 5 - значения $\omega$ и соответствующие значения $k$ для $n = 10$}}
		\end{table}
		\clearpage
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|}
				\hline
				$\omega$ & $k$\\
				\hline
				1.10 &  944\\ \hline
				1.20 &  769\\ \hline
				1.30 &  620\\ \hline
				1.40 &  493\\ \hline
				1.50 &  383\\ \hline
				1.60 &  286\\ \hline
				1.70 &  201\\ \hline
				1.80 &  125\\ \hline
				1.90 &  93\\ \hline
			\end{tabular}
			\caption*{\small{Таблица 6 - значения $\omega$ и соответствующие значения $k$ для $n = 50$}}
		\end{table}
		
		Для вычислений выберем $\omega = 1.6$ для $n=10$ и $\omega = 1.90$ для $n=50$. Составим таблицы результатов.
		в которых будем сравнивать значения метода прогонки и метода верхней релаксации для точки $i,\; i = \overline{0, n-1}$,
		найдём модуль их разности и значение $k$:
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				$i$ & $y_i$ & $y_i^k$ & $\epsilon$ & $k$\\
				\hline
				0 & 0.106769 & 0.107336 & 0.000567 & 11 \\
				\hline
				1 & 0.184376 & 0.185502 & 0.001126 & 11 \\
				\hline
				2 & 0.235499 & 0.237047 & 0.001549 & 11 \\
				\hline
				3 & 0.263158 & 0.264915 & 0.001756 & 11 \\
				\hline
				4 & 0.270334 & 0.272060 & 0.001726 & 11 \\
				\hline
				5 & 0.259690 & 0.261174 & 0.001484 & 11 \\
				\hline
				6 & 0.233435 & 0.234526 & 0.001091 & 11 \\
				\hline
				7 & 0.193281 & 0.193918 & 0.000637 & 11 \\
				\hline
				8 & 0.140478 & 0.140705 & 0.000227 & 11 \\
				\hline
				9 & 0.075876 & 0.075852 & 0.000024 & 11 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 7 - значения метода верхней релаксации для $n = 10$}}
		\end{table}
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				$i$ & $y_i$ & $y_i^k$ & $\epsilon$ & $k$\\
				\hline
				0 & 0.022665 & 0.022656 & 0.000008 & 93 \\
				\hline
				10 & 0.185482 & 0.185453 & 0.000029 & 93 \\
				\hline
				20 & 0.245190 & 0.245161 & 0.000029 & 93 \\
				\hline
				30 & 0.223275 & 0.223260 & 0.000016 & 93 \\
				\hline
				40 & 0.137813 & 0.137810 & 0.000003 & 93 \\
				\hline
				49 & 0.015952 & 0.015952 & 0.000000 & 93 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 8 - значения метода верхней релаксации для $n = 50$}}
		\end{table}
		\clearpage
		\subsection{Метод наискорейшего спуска}
		\hspace{1.25cm}Существуют итерационные методы, позволяющие за счет некоторой дополнительной работы на 
		каждом шаге итераций автоматически настраиваться на оптимальную скорость сходимости. К их числу относятся методы, основанные 
		на замене системы \eqref{6} эквивалентной задачей минимизации некоторого функционала.
		
		Опишем итерационный метод наискорейшего спуска. Будем двигаться из точки началь\-ного приближения $x^0$ в направлении наибыстрейшего убывания функционала $F$, 
		то есть следующее приближение будем разыскивать так: $x^1=x^0 - \tau \mathrm { grad } F(x^0).$ Формула:
		\begin{equation}
			F'_{x_i}(x) = 2\sum\limits_{j=1}^{n}a_{ij}x_j - 2b_i;
			\label{11}
		\end{equation}
		, которая является производной функции $F(x)$ по переменной $x_i$, показывает, что $\mathrm { grad } F(x^0)=2(Ax^0-b).$ 
		Вектор $r_0 = Ax^0-b$ принято называть невязкой. Для сокращения записей удобно обозначить $2\tau$ вновь через $\tau.$ 
		Таким образом, $x^1=x^0-\tau r^0.$
		
		Параметр $\tau$ выберем так, чтобы значение $F(x^1)$ было минимальным. Получим $F(x^1)=F(x^0-\tau r^0)=F(x^0)-2\tau(r^0,r^0)+\tau^2(Ar^0,r^0),$ 
		следовательно, минимум $F(x^1)$ достигается при $\tau =\tau_*=\displaystyle\frac{(r^0, r^0)}{(Ar^0, r^0)}.$
		
		Таким образом, мы пришли к следующему итерационнму методу:
		\begin{equation}
			x^{k+1}=x^k-\tau_* r^k, \quad r^k=Ax^k-b, \quad \tau_*=\displaystyle\frac{(r^k, r^k)}{(Ar^k, r^k)}, \; k=0,1, \dots \;.
			\label{12}
		\end{equation}
		
		Метод ($12$) называют методом наискорейшего спуска. По сравнению с методом простой итерации этот метод требует на каждом шаге итераций 
		проведения дополнительной работы по вычислению параметра $\tau_*.$ Вследствие этого происходит адаптация к оптимальной скорости сходимости.
		
		Составим таблицы результатов для $n = 10$, $n = 50$,
		в которых будем сравнивать значения метода прогонки и метода верхней релаксации для точки $i,\; i = \overline{0, n-1}$,
		найдём модуль их разности и значение $k$:
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				$i$ & $y_i$ & $y_i^{k}$ & $\epsilon$ & $k$ \\
				\hline
				0 & 0.106769 & 0.105365 & 0.001404 & 78 \\
				\hline
				1 & 0.184376 & 0.181841 & 0.002535 & 78 \\
				\hline
				2 & 0.235499 & 0.232225 & 0.003274 & 78 \\
				\hline
				3 & 0.263158 & 0.259567 & 0.003591 & 78 \\
				\hline
				4 & 0.270334 & 0.266804 & 0.003530 & 78 \\
				\hline
				5 & 0.259690 & 0.256517 & 0.003173 & 78 \\
				\hline
				6 & 0.233435 & 0.230798 & 0.002637 & 78 \\
				\hline
				7 & 0.193281 & 0.191326 & 0.001955 & 78 \\
				\hline
				8 & 0.140478 & 0.139067 & 0.001412 & 78 \\
				\hline
				9 & 0.075876 & 0.075415 & 0.000461 & 78 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 9 - значения метода наискорейшего спуска для $n = 10$}}
		\end{table}
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				$i$ & $y_i$ & $y_i^{k}$ & $\epsilon$ & $k$ \\
				\hline
				0 & 0.022665 & 0.022583 & 0.000081 & 816 \\
				\hline
				1 & 0.044129 & 0.043967 & 0.000161 & 816 \\
				\hline
				2 & 0.064402 & 0.064163 & 0.000240 & 816 \\
				\hline
				3 & 0.083498 & 0.083182 & 0.000316 & 816 \\
				\hline
				4 & 0.101429 & 0.101039 & 0.000389 & 816 \\
				\hline
				5 & 0.118210 & 0.117750 & 0.000460 & 816 \\
				\hline
				6 & 0.133858 & 0.133331 & 0.000527 & 816 \\
				\hline
				7 & 0.148390 & 0.147800 & 0.000590 & 816 \\
				\hline
				8 & 0.161825 & 0.161176 & 0.000649 & 816 \\
				\hline
				9 & 0.174182 & 0.173479 & 0.000703 & 816 \\
				\hline
				10 & 0.185482 & 0.184730 & 0.000753 & 816 \\
				\hline
				20 & 0.245190 & 0.244231 & 0.000959 & 816 \\
				\hline
				30 & 0.223275 & 0.222550 & 0.000725 & 816 \\
				\hline
				40 & 0.137813 & 0.137481 & 0.000332 & 816 \\
				\hline
				49 & 0.015952 & 0.015923 & 0.000029 & 816 \\
				\hline
			\end{tabular}
			\caption*{\small{Таблица 10 - значения метода наискорейшего спуска для $n = 50$}}
		\end{table}
		\clearpage
		\section{Выводы}
		\hspace{1.25cm}В процессе выполнения работы были изучены методы решения заданной системы линейных алгебраических уравнений вида:
		\begin{equation*}
			\begin{cases}
				&(a_1 + a_2 + h^2g_1)y_1 - a_2y_2 = f_1h^2,\\
				&\hspace{1cm}\dots \quad \dots \quad \dots \quad \dots\\
				&-a_iy_{i-1} + (a_i + a_{i+1} + h^2g_i)y_i - a_{i+1}y_{i+1} = f_ih^2,\\
				&\hspace{1cm}\dots \quad \dots \quad \dots \quad \dots\\
				&(a_{n-1} + a_{n} + h^2g_{n-1})y_{n-1} - a_{n-1}y_{n-2} = f_{n-1}h^2.\\
			\end{cases}
		\end{equation*}
		при помощи:
		\begin{enumerate}[label = \arabic*.]
			\item метод прогонки.
			\item метод Зейделя.
			\item метод верхней релаксации.
			\item метод наискорейшего спуска.
		\end{enumerate}
		
		После вычисления результатов решения системы линейных алгебраических уравнений можно сделать вывод, 
		что наилучшим методом для решения является метод верхней релакса\-ции при итерационном параметре $\omega = 1.6$ для системы из 10 уравнений и $\omega = 1.90$ для системы из 50 уравнений. 
		Данный метод показывается наилучшие результа\-ты вычисления корней системы за наименьшее количество итераций.
	}
	\clearpage
	\section{Cписок литературы}
	\begin{enumerate}
		\item Глазырина Л.Л., Карчевский М.М. Численные методы: учебное пособие. — Казань: Казан.
		ун-т, 2012. — 122 
		\item Глазырина Л.Л.. Практикум по курсу «Численные методы». Решение
		систем линейных уравнений: учеб. пособие. — Казань: Изд-во Казан. ун-та, 2017. — 52 с.
	\end{enumerate}
	\clearpage
	\section{Листинг программы}
	\lstinputlisting[language=C++]{./header.hpp}
	\lstinputlisting[language=C++]{./main.cpp}
\end{document}